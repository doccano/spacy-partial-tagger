[paths]
train = "./train.spacy"
dev = "./dev.spacy"
init_tok2vec = null
vectors = null

[corpora]

[corpora.train]
@readers = "spacy.Corpus.v1"
path = ${paths.train}
gold_preproc = true

[corpora.dev]
@readers = "spacy.Corpus.v1"
path = ${paths.dev}
gold_preproc = true

[system]
gpu_allocator = null
seed = 0

[nlp]
lang = "en"
pipeline = ["partial_ner"]
tokenizer = {"@tokenizers": "transformer_tokenizer.v1"}
disabled = []
before_creation = null
after_creation = null
after_pipeline_creation = null
batch_size = 15

[nlp.tokenizer]
model_name = "roberta-base"

[components]

[components.partial_ner]
factory = "partial_ner"
padding_index = -1

[components.partial_ner.model]
@architectures = "spacy-partial-tagger.PartialTagger.v1"
nI = 768
nO = null
dropout = 0.2
padding_index = ${components.partial_ner.padding_index}

[components.partial_ner.model.tok2vec]
@architectures = "spacy-partial-tagger.Tok2VecTransformer.v1"
model_name = "roberta-base"

[training]
dev_corpus = "corpora.dev"
train_corpus = "corpora.train"
seed = ${system.seed}
gpu_allocator = ${system.gpu_allocator}
accumulate_gradient = 1
patience = 9360
max_epochs = 20
eval_frequency = 936
frozen_components = []
before_to_disk = null

[training.batcher]
@batchers = "spacy.batch_by_sequence.v1"
size = 15
get_length = null

[training.logger]
@loggers = "spacy.ConsoleLogger.v1"
progress_bar = false

[training.optimizer]
@optimizers = "Adam.v1"
beta1 = 0.9
beta2 = 0.999
L2_is_weight_decay = false
use_averages = false
grad_clip = 5.0

[training.optimizer.learn_rate]
@schedules = "slanted_triangular.v1"
max_rate = 0.00002
num_steps = 18721
cut_frac = 0.1
ratio = 16
t = -1

[training.score_weights]
ents_per_type = null
ents_f = 1.0
ents_p = 0.0
ents_r = 0.0

[pretraining]

[initialize]

[initialize.components]

[initialize.tokenizer]
